<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<html>
<head>

<title>MPATE-GE 2618 Final Project</title>

<link href="mfbasic.css" rel="stylesheet" type="text/css" />
</head>

<body>
<div id="top"></div>
<div id="container">
<div id="content">

<!--Do not edit anything above this-->

<h1>3D Sound Visualizer</h1>
<h2>Emmett Butler and David Coss</h2>

<h3>Summary</h3>
<p>This project provides realtime 3d visualization of mono and stereo WAV audio streams. The visualizations created are mainly abstract and can be considered an emulation of the iTunes (or, more accurately, WMP) visualizer. It uses OpenGL, freeglut, portaudio and libsndfile to create these visuals in real time.</p>

<p>Invoked from the command line, the visualizer takes the name of an audio file and a number of flags specifying graphical behaviors. These can range from the basic flat waveform to a colorful, dynamic shape of constantly-changing data.</p>

<p>The main challenge of the project (beyond learning a book's worth of 3D graphics theory and practice) was to properly synchronize the audio streaming with the graphics rendering loop. This is accomplished using a shared buffer contianing a number of renderable "screens" worth of audio waveform data. The audio streamer acts as a server that fills free slots in the buffer, and the graphics rendering client pulls data from the filled slots. Since the audio runs at a much faster rate than the graphics, the audio ends up waiting around a bit. This is ok, since it has plenty of heavy number-crunching capacity as visualizations grow more advanced.</p>

<h3>Usage</h3>
<pre>
    <b>Visualizer &lt;soundfile&gt; [-w hamming|hann|cosine] [-c] [-s circle|line|wave] [-t] [-r auto|mouse]</b>
        soundfile : the file to be played
        -w : the windowing function for the waveform
        -c : enable flashing colors
        -r : rotation mode
        -s : base waveform shape
        -t : exponential frame translation
</pre>
<p><b>&lt;soundfile&gt;</b> must be a mono or stereo audio file. Supported formats include WAV, AIFF, and FLAC. For a list of file formats that are compatible with libsndfile but are untested with this program, see <a href="http://www.mega-nerd.com/libsndfile/">the libsndfile documentation</a>.
<p><b>-w</b> is an optional argument to specify a <a href="http://en.wikipedia.org/wiki/Hann_function">windowing function</a> for the waveform, giving the oscillator a "tapering" effect. Valid windowing functions are "hann", "hamming", and "cosine". Leaving out this flag or specifying an invalid window will result in no window being applied.<br />

<p>To test the visualizer, use one of the included test audio files in testfiles. For example: <b>./Visualizer testfiles/sonic.wav -c -t -s circle</b></p>

<p>The arrow keys can be used to manually move the camera forward, back, left, and right. When the -r mouse option is used, the mouse can be used to manually rotate the waveform.</p>

<h3>Compiling</h3>
The project comes with a makefile with targets for linux and MacOS. The linux target is tested and works with jack, alsa, freeglut3 and libgl. Note that the project requires OpenGL 2.1 or later.

<h3>API</h3>
<h4>Starting and ending audio</h4>
<pre>
    bool startAudio(PaStream *stream, const char* filename, const char* windowname);

    void endAudio(PaStream *stream);
</pre>
<p>Handles all Portaudio and libsndfile functions necessary to begin or stop playback of the file with the specified file name. Example implementation:<p>
<pre>
    PaStream *stream;
    startAudio(PaStream *stream, "test.wav", "hamming");
</pre>

<h4>Reading audio</h4>
<p>All audio samples are stored in Packets. The packet structure is defined in Visualizer.h. Packet.frames is a 2D array of floats; the first dimension specifies the audio frame and the second dimension specifies the channel. Packet.free specifies whether the frames array is in read or write mode. If Packet.free is true, Packet.frames can be written to; if Packet.free is false, it can be read.</p>
<pre>
    /* Visualizer.h */
    #define PACKET_SIZE 256
    #define PAC_CHANNELS 2

    typedef struct _packet{
        float frames[PACKET_SIZE][PAC_CHANNELS];
        bool free;  // is this packet free to overwrite
        int order;  // where in the sequence of samples is this packet
        float averageAmp;
    } Packet;
</pre>

An array of Packets should be used in order to compensate for the framerate differences between the GL thread and the Portaudio thread. This is implemented in audio_helper.cpp and graphics_helper.cpp as <b>sharedBuffer</b>.<br />

<h4>Rendering Graphics</h4>
<p>The main bulk of the graphics work happens in the RenderScene() function. This function is responsible for drawing the array of pre-created prisms representing the audio frames to the screen. It scales each prism proportionally to the amplitude value of the corresponding frame. It also performs a few scaling and translation transformations based on other audio parameters. To accomplish this, it uses the GLMatrixStack class from GLTools to help keep track of the various visual transformations.</p>
<p>Read the code:
<a href="http://github.com/emmett9001/opengl_audio_vis">On Github</a>

<br />
<img src="images/screencap.png"></img>

<!--Don't edit anything below here-->
</div>
<div id="footer">MPATE-GE 2618 C Programming for Music Technology Final Project</div>

</div>
</body>
</html>
